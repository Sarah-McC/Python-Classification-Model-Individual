{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np            # data science essentials\n",
    "import pandas as pd             # data science essentials\n",
    "import matplotlib.pyplot as plt # essential graphical output\n",
    "import seaborn as sns           # enhanced graphical output\n",
    "import statsmodels.formula.api as smf # regression modeling\n",
    "import sklearn.linear_model # linear models\n",
    "from sklearn.metrics import roc_auc_score # roc_auc_score\n",
    "from sklearn.model_selection import train_test_split # train/test split\n",
    "from sklearn.preprocessing import StandardScaler # standard scaler\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN Classifier\n",
    "from sklearn.neighbors import KNeighborsRegressor # KNN Regression\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "import statsmodels.formula.api as smf                # logistic regression\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.ensemble import GradientBoostingClassifier # Gradient Bossting Regression\n",
    "from sklearn.ensemble import RandomForestClassifier # RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV # CV using Grid Search\n",
    "from sklearn.metrics import make_scorer              # customizable scorer\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import export_graphviz             # exports graphics\n",
    "from six import StringIO           # saves objects in memory\n",
    "from IPython.display import Image                    # displays on frontend\n",
    "import pydotplus                                     # interprets dot objects\n",
    "from sklearn.model_selection import RandomizedSearchCV     # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer              # customizable scorer\n",
    "\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "# specifying file name\n",
    "file = 'Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "\n",
    "# reading the file into Python\n",
    "original_df = pd.read_excel(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dropped dataset \n",
    "original_df = original_df.dropna()\n",
    "\n",
    "original_df.isnull().sum().sum()\n",
    "\n",
    "original_df.to_excel(\"A1_original_df_wo_na.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting emails\n",
    "\n",
    "# safety measure in case of multiple concatenations\n",
    "original_df = pd.read_excel('A1_original_df_wo_na.xlsx')\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in original_df.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_email = original_df.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a DataFrame \n",
    "email_df = pd.DataFrame(placeholder_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating with original DataFrame\n",
    "\n",
    "# renaming column to concatenate\n",
    "email_df.columns = ['0' , 'email_domain']\n",
    "\n",
    "\n",
    "# concatenating personal_email_domain \n",
    "original_df = pd.concat([original_df, email_df['email_domain']],\n",
    "                     axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "personal        845\n",
       "professional    678\n",
       "junk            376\n",
       "Name: domain_group, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# email domain types\n",
    "personal_email_domains = ['@gmail.com', '@yahoo.com', '@protonmail.com']\n",
    "junk_email_domains  = ['@me.com', '@aol.com', '@hotmail.com',\n",
    "                       '@live.com', '@msn.com', '@passport.com']\n",
    "prof_email_domains  = ['@mmm.com', '@amex.com', '@apple.com',\n",
    "                       '@boeing.com', '@caterpillar.com', '@chevron.com',\n",
    "                       '@cisco.com', '@cocacola.com', '@disney.com', \n",
    "                       '@dupont.com', '@exxon.com', '@ge.org', \n",
    "                       '@goldmansacs.com', '@homedepot.com', '@ibm.com', \n",
    "                       '@intel.com', '@jnj.com', '@jpmorgan.com', \n",
    "                       '@mcdonalds.com', '@merck.com', '@microsoft.com', \n",
    "                       '@nike.com', '@pfizer.com', '@pg.com', \n",
    "                       '@travelers.com', '@unitedtech.com', '@unitedhealth.com',\n",
    "                       '@verizon.com', '@visa.com', '@walmart.com']\n",
    "\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "\n",
    "# looping to group observations by domain type\n",
    "for domain in original_df['email_domain']:\n",
    "    \n",
    "    if '@' + str(domain) in personal_email_domains:\n",
    "        placeholder_lst.append('personal')\n",
    "        \n",
    "\n",
    "    elif '@' + str(domain) in junk_email_domains:\n",
    "        placeholder_lst.append('junk')\n",
    "        \n",
    "        \n",
    "    elif '@' + str(domain) in prof_email_domains:\n",
    "        placeholder_lst.append('professional')\n",
    "\n",
    "\n",
    "    else:\n",
    "        print('Unknown')\n",
    "\n",
    "\n",
    "# concatenating with original DataFrame\n",
    "original_df['domain_group'] = pd.Series(placeholder_lst)\n",
    "\n",
    "\n",
    "# checking results\n",
    "original_df['domain_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for domain group\n",
    "dummies = pd.get_dummies(original_df['domain_group'])\n",
    "\n",
    "# concatenating personal_email_domain with friends DataFrame\n",
    "original_df = pd.concat([original_df, dummies],\n",
    "                     axis = 1)\n",
    "\n",
    "# dropping categorical variables after they've been encoded\n",
    "original_df = original_df.drop('domain_group', axis = 1)\n",
    "\n",
    "# verifying\n",
    "original_df.head()\n",
    "\n",
    "# converting the dummies \n",
    "original_df['junk'] = np.int64(original_df['junk'])\n",
    "original_df['personal'] = np.int64(original_df['personal'])\n",
    "original_df['professional'] = np.int64(original_df['professional'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier threshholds\n",
    "REVENUE_HI = 5000\n",
    "TOTAL_MEALS_ORDERED_HI = 200\n",
    "UNIQUE_MEALS_PURCH_HI = 9\n",
    "CONTACTS_W_CUSTOMER_SERVICE_HI = 10.5   \n",
    "CONTACTS_W_CUSTOMER_SERVICE_LOW = 2.5    \n",
    "AVG_TIME_PER_SITE_VISIT_HI = 225\n",
    "CANCELLATIONS_BEFORE_NOON_HI = 5        \n",
    "CANCELLATIONS_AFTER_NOON_HI = 1.5        \n",
    "MOBILE_LOGINS_HI = 6.5\n",
    "MOBILE_LOGINS_LOW = 4.5\n",
    "PC_LOGINS_HI = 2.5\n",
    "PC_LOGINS_LOW = 0.5\n",
    "WEEKLY_PLAN_HI = 18\n",
    "EARLY_DELIVERIES_HI = 5\n",
    "LATE_DELIVERIES_HI = 8\n",
    "AVG_PREP_VID_TIME_HI =250\n",
    "MASTER_CLASSES_ATTENDED_HI = 1.5\n",
    "MEDIAN_MEAL_RATING_HI = 4\n",
    "AVG_CLICKS_PER_VISIT_LOW = 9\n",
    "AVG_CLICKS_PER_VISIT_HI = 18\n",
    "TOTAL_PHOTOS_VIEWED_HI =300\n",
    "\n",
    "##############################################################################\n",
    "## Feature Engineering (outlier thresholds)                                 ##\n",
    "##############################################################################\n",
    "\n",
    "# developing features (columns) for outliers\n",
    "\n",
    "for index, value in original_df.iterrows():\n",
    "   \n",
    "    # REVENUE\n",
    "    if original_df.loc[index, 'REVENUE'] > REVENUE_HI:\n",
    "        original_df.loc[index, 'out_REVENUE'] = 1\n",
    "    else:\n",
    "        original_df.loc[index, 'out_REVENUE'] = 0\n",
    "    \n",
    "    # TOTAL MEALS ORDERED\n",
    "    if original_df.loc[index, 'TOTAL_MEALS_ORDERED'] > TOTAL_MEALS_ORDERED_HI:\n",
    "        original_df.loc[index, 'out_TOTAL_MEALS_ORDERED'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_TOTAL_MEALS_ORDERED']= 0\n",
    "    \n",
    "     # Unique Meals Purchase\n",
    "    if original_df.loc[index, 'UNIQUE_MEALS_PURCH'] > UNIQUE_MEALS_PURCH_HI:\n",
    "        original_df.loc[index, 'out_UNIQUE_MEALS_PURCH'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_UNIQUE_MEALS_PURCH']= 0\n",
    "    \n",
    "     # AVERAGE TIME PER SITE VISIT\n",
    "    if original_df.loc[index, 'AVG_TIME_PER_SITE_VISIT'] > AVG_TIME_PER_SITE_VISIT_HI:\n",
    "        original_df.loc[index, 'out_AVG_TIME_PER_SITE_VISIT'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_AVG_TIME_PER_SITE_VISIT']= 0\n",
    "    \n",
    "    # CONTACTS WITH CUSTOMER SERVICE\n",
    "    if original_df.loc[index, 'CONTACTS_W_CUSTOMER_SERVICE'] > CONTACTS_W_CUSTOMER_SERVICE_HI:\n",
    "        original_df.loc[index, 'out_CONTACTS_W_CUSTOMER_SERVICE'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_CONTACTS_W_CUSTOMER_SERVICE']= 0\n",
    "    \n",
    "    #CONTACTS WITH CUSTOMER SERVICE\n",
    "    if original_df.loc[index, 'CONTACTS_W_CUSTOMER_SERVICE'] > CONTACTS_W_CUSTOMER_SERVICE_LOW:\n",
    "        original_df.loc[index, 'out_CONTACTS_W_CUSTOMER_SERVICE'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_CONTACTS_W_CUSTOMER_SERVICE']= 0\n",
    "    \n",
    "    # CANCELLATIONS BEFORE NOON\n",
    "    if original_df.loc[index, 'CANCELLATIONS_BEFORE_NOON'] > CANCELLATIONS_BEFORE_NOON_HI:\n",
    "        original_df.loc[index, 'out_CANCELLATIONS_BEFORE_NOON'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_CANCELLATIONS_BEFORE_NOON']= 0  \n",
    "    \n",
    "    #CANCELLATIONS_AFTER_NOON\n",
    "    if original_df.loc[index, 'CANCELLATIONS_AFTER_NOON'] > CANCELLATIONS_AFTER_NOON_HI:\n",
    "        original_df.loc[index, 'out_CANCELLATIONS_AFTER_NOON'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_CANCELLATIONS_AFTER_NOON']= 0  \n",
    "    \n",
    "    #MOBILE LOGINS\n",
    "    if original_df.loc[index, 'MOBILE_LOGINS'] > MOBILE_LOGINS_HI:\n",
    "        original_df.loc[index, 'out_MOBILE_LOGINS'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_MOBILE_LOGINS']= 0  \n",
    "\n",
    "    #MOBILE LOGINS\n",
    "    if original_df.loc[index, 'MOBILE_LOGINS'] > MOBILE_LOGINS_LOW:\n",
    "        original_df.loc[index, 'out_MOBILE_LOGINS'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_MOBILE_LOGINS']= 0\n",
    "    \n",
    "     #PC LOGINS\n",
    "    if original_df.loc[index, 'PC_LOGINS'] > PC_LOGINS_HI:\n",
    "        original_df.loc[index, 'out_PC_LOGINS'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_PC_LOGINS']= 0  \n",
    "    \n",
    "    #PC LOGINS\n",
    "    if original_df.loc[index, 'PC_LOGINS'] > PC_LOGINS_LOW:\n",
    "        original_df.loc[index, 'out_PC_LOGINS'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_PC_LOGINS']= 0  \n",
    "    \n",
    "    #WEEKLY PLAN\n",
    "    if original_df.loc[index, 'WEEKLY_PLAN'] > WEEKLY_PLAN_HI:\n",
    "        original_df.loc[index, 'out_WEEKLY_PLAN'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_WEEKLY_PLAN']= 0\n",
    "    \n",
    "     #WEEKLY PLAN\n",
    "    if original_df.loc[index, 'EARLY_DELIVERIES'] > EARLY_DELIVERIES_HI:\n",
    "        original_df.loc[index, 'out_EARLY_DELIVERIES'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_EARLY_DELIVERIES']= 0\n",
    "    \n",
    "    #WEEKLY PLAN\n",
    "    if original_df.loc[index, 'LATE_DELIVERIES'] > LATE_DELIVERIES_HI:\n",
    "        original_df.loc[index, 'out_LATE_DELIVERIES'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_LATE_DELIVERIES']= 0\n",
    "    \n",
    "    #AVG_PREP_VID_TIME\n",
    "    if original_df.loc[index, 'AVG_PREP_VID_TIME'] > AVG_PREP_VID_TIME_HI:\n",
    "        original_df.loc[index, 'out_AVG_PREP_VID_TIME'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_AVG_PREP_VID_TIME']= 0\n",
    "    \n",
    "    #MASTER_CLASSES_ATTENDED\n",
    "    if original_df.loc[index, 'MASTER_CLASSES_ATTENDED'] > MASTER_CLASSES_ATTENDED_HI:\n",
    "        original_df.loc[index, 'out_MASTER_CLASSES_ATTENDED'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_MASTER_CLASSES_ATTENDED']= 0\n",
    "    \n",
    "    #MEDIAN_MEAL_RATING\n",
    "    if original_df.loc[index, 'MEDIAN_MEAL_RATING'] > MEDIAN_MEAL_RATING_HI:\n",
    "        original_df.loc[index, 'out_MEDIAN_MEAL_RATING'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_MEDIAN_MEAL_RATING']= 0\n",
    "    \n",
    "    #AVG_CLICKS_PER_VISIT\n",
    "    if original_df.loc[index, 'AVG_CLICKS_PER_VISIT'] > AVG_CLICKS_PER_VISIT_LOW:\n",
    "        original_df.loc[index, 'out_AVG_CLICKS_PER_VISIT'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_AVG_CLICKS_PER_VISIT']= 0\n",
    "    \n",
    "    #AVG_CLICKS_PER_VISIT\n",
    "    if original_df.loc[index, 'AVG_CLICKS_PER_VISIT'] > AVG_CLICKS_PER_VISIT_HI:\n",
    "        original_df.loc[index, 'out_AVG_CLICKS_PER_VISIT'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_AVG_CLICKS_PER_VISIT']= 0\n",
    "    \n",
    "    #AVG_CLICKS_PER_VISIT\n",
    "    if original_df.loc[index, 'TOTAL_PHOTOS_VIEWED'] > TOTAL_PHOTOS_VIEWED_HI:\n",
    "        original_df.loc[index, 'out_TOTAL_PHOTOS_VIEWED'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_TOTAL_PHOTOS_VIEWED']= 0\n",
    "    \n",
    "    #AVG_CLICKS_PER_VISIT\n",
    "    if original_df.loc[index, 'TOTAL_PHOTOS_VIEWED'] > TOTAL_PHOTOS_VIEWED_HI:\n",
    "        original_df.loc[index, 'out_TOTAL_PHOTOS_VIEWED'] = 1\n",
    "    else:\n",
    "        original_df.loc[index,'out_TOTAL_PHOTOS_VIEWED']= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving feature-rich dataset in Excel\n",
    "original_df.to_excel('original_df_feature_rich.xlsx',\n",
    "                 index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CROSS_SELL_SUCCESS                 1.00\n",
       "professional                       0.20\n",
       "CANCELLATIONS_BEFORE_NOON          0.16\n",
       "MOBILE_NUMBER                      0.10\n",
       "TASTES_AND_PREFERENCES             0.08\n",
       "REFRIGERATED_LOCKER                0.07\n",
       "out_CANCELLATIONS_BEFORE_NOON      0.06\n",
       "out_CONTACTS_W_CUSTOMER_SERVICE    0.05\n",
       "out_AVG_PREP_VID_TIME              0.05\n",
       "PACKAGE_LOCKER                     0.04\n",
       "personal                           0.04\n",
       "MASTER_CLASSES_ATTENDED            0.04\n",
       "PC_LOGINS                          0.04\n",
       "CONTACTS_W_CUSTOMER_SERVICE        0.04\n",
       "out_MEDIAN_MEAL_RATING             0.03\n",
       "AVG_PREP_VID_TIME                  0.03\n",
       "MEDIAN_MEAL_RATING                 0.03\n",
       "out_EARLY_DELIVERIES               0.02\n",
       "EARLY_DELIVERIES                   0.02\n",
       "out_LATE_DELIVERIES                0.02\n",
       "LARGEST_ORDER_SIZE                 0.02\n",
       "REVENUE                            0.01\n",
       "AVG_TIME_PER_SITE_VISIT            0.01\n",
       "TOTAL_MEALS_ORDERED                0.01\n",
       "LATE_DELIVERIES                    0.00\n",
       "out_REVENUE                        0.00\n",
       "out_MASTER_CLASSES_ATTENDED        0.00\n",
       "UNIQUE_MEALS_PURCH                 0.00\n",
       "TOTAL_PHOTOS_VIEWED                0.00\n",
       "PRODUCT_CATEGORIES_VIEWED         -0.00\n",
       "out_WEEKLY_PLAN                   -0.00\n",
       "out_TOTAL_PHOTOS_VIEWED           -0.01\n",
       "WEEKLY_PLAN                       -0.01\n",
       "out_UNIQUE_MEALS_PURCH            -0.02\n",
       "out_AVG_TIME_PER_SITE_VISIT       -0.02\n",
       "AVG_CLICKS_PER_VISIT              -0.04\n",
       "MOBILE_LOGINS                     -0.05\n",
       "out_TOTAL_MEALS_ORDERED           -0.05\n",
       "CANCELLATIONS_AFTER_NOON          -0.05\n",
       "out_CANCELLATIONS_AFTER_NOON      -0.06\n",
       "out_AVG_CLICKS_PER_VISIT          -0.07\n",
       "junk                              -0.28\n",
       "out_MOBILE_LOGINS                   NaN\n",
       "out_PC_LOGINS                       NaN\n",
       "Name: CROSS_SELL_SUCCESS, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr = original_df.corr(method= 'pearson').round(decimals=2)\n",
    "\n",
    "df_corr['CROSS_SELL_SUCCESS'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring explanatory variables\n",
    "original_df_data = original_df.drop('CROSS_SELL_SUCCESS', axis = 1)\n",
    "\n",
    "\n",
    "# declaring response variable\n",
    "original_df_target = original_df.loc[ : , 'CROSS_SELL_SUCCESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            original_df_data,\n",
    "            original_df_target,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = original_df_target)\n",
    "\n",
    "\n",
    "# merging training data for statsmodels\n",
    "original_df_train = pd.concat([x_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REVENUE + \n",
      " CROSS_SELL_SUCCESS + \n",
      " NAME + \n",
      " EMAIL + \n",
      " FIRST_NAME + \n",
      " FAMILY_NAME + \n",
      " TOTAL_MEALS_ORDERED + \n",
      " UNIQUE_MEALS_PURCH + \n",
      " CONTACTS_W_CUSTOMER_SERVICE + \n",
      " PRODUCT_CATEGORIES_VIEWED + \n",
      " AVG_TIME_PER_SITE_VISIT + \n",
      " MOBILE_NUMBER + \n",
      " CANCELLATIONS_BEFORE_NOON + \n",
      " CANCELLATIONS_AFTER_NOON + \n",
      " TASTES_AND_PREFERENCES + \n",
      " PC_LOGINS + \n",
      " MOBILE_LOGINS + \n",
      " WEEKLY_PLAN + \n",
      " EARLY_DELIVERIES + \n",
      " LATE_DELIVERIES + \n",
      " PACKAGE_LOCKER + \n",
      " REFRIGERATED_LOCKER + \n",
      " AVG_PREP_VID_TIME + \n",
      " LARGEST_ORDER_SIZE + \n",
      " MASTER_CLASSES_ATTENDED + \n",
      " MEDIAN_MEAL_RATING + \n",
      " AVG_CLICKS_PER_VISIT + \n",
      " TOTAL_PHOTOS_VIEWED + \n",
      " email_domain + \n",
      " junk + \n",
      " personal + \n",
      " professional + \n",
      " out_REVENUE + \n",
      " out_TOTAL_MEALS_ORDERED + \n",
      " out_UNIQUE_MEALS_PURCH + \n",
      " out_AVG_TIME_PER_SITE_VISIT + \n",
      " out_CONTACTS_W_CUSTOMER_SERVICE + \n",
      " out_CANCELLATIONS_BEFORE_NOON + \n",
      " out_CANCELLATIONS_AFTER_NOON + \n",
      " out_MOBILE_LOGINS + \n",
      " out_PC_LOGINS + \n",
      " out_WEEKLY_PLAN + \n",
      " out_EARLY_DELIVERIES + \n",
      " out_LATE_DELIVERIES + \n",
      " out_AVG_PREP_VID_TIME + \n",
      " out_MASTER_CLASSES_ATTENDED + \n",
      " out_MEDIAN_MEAL_RATING + \n",
      " out_AVG_CLICKS_PER_VISIT + \n",
      " out_TOTAL_PHOTOS_VIEWED + \n"
     ]
    }
   ],
   "source": [
    "for val in original_df:\n",
    "    print(f\" {val} + \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.586223\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>CROSS_SELL_SUCCESS</td> <th>  No. Observations:  </th>  <td>  1899</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>Logit</td>       <th>  Df Residuals:      </th>  <td>  1860</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>        <th>  Df Model:          </th>  <td>    38</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 25 Jan 2021</td>  <th>  Pseudo R-squ.:     </th>  <td>0.06737</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:48:03</td>      <th>  Log-Likelihood:    </th> <td> -1113.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>        <th>  LL-Null:           </th> <td> -1193.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>4.695e-17</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>   -2.5981</td> <td>    1.335</td> <td>   -1.946</td> <td> 0.052</td> <td>   -5.215</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REVENUE</th>                         <td>   -0.0002</td> <td> 8.81e-05</td> <td>   -1.837</td> <td> 0.066</td> <td>   -0.000</td> <td> 1.09e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TOTAL_MEALS_ORDERED</th>             <td>    0.0043</td> <td>    0.002</td> <td>    2.655</td> <td> 0.008</td> <td>    0.001</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UNIQUE_MEALS_PURCH</th>              <td>   -0.0008</td> <td>    0.022</td> <td>   -0.036</td> <td> 0.971</td> <td>   -0.045</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CONTACTS_W_CUSTOMER_SERVICE</th>     <td>    0.0437</td> <td>    0.024</td> <td>    1.820</td> <td> 0.069</td> <td>   -0.003</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PRODUCT_CATEGORIES_VIEWED</th>       <td>    0.0010</td> <td>    0.017</td> <td>    0.061</td> <td> 0.951</td> <td>   -0.032</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AVG_TIME_PER_SITE_VISIT</th>         <td>    0.0011</td> <td>    0.001</td> <td>    0.945</td> <td> 0.345</td> <td>   -0.001</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MOBILE_NUMBER</th>                   <td>    0.6755</td> <td>    0.151</td> <td>    4.471</td> <td> 0.000</td> <td>    0.379</td> <td>    0.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_BEFORE_NOON</th>       <td>    0.3005</td> <td>    0.043</td> <td>    6.911</td> <td> 0.000</td> <td>    0.215</td> <td>    0.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_AFTER_NOON</th>        <td>   -0.2060</td> <td>    0.155</td> <td>   -1.326</td> <td> 0.185</td> <td>   -0.511</td> <td>    0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TASTES_AND_PREFERENCES</th>          <td>    0.4416</td> <td>    0.113</td> <td>    3.922</td> <td> 0.000</td> <td>    0.221</td> <td>    0.662</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_LOGINS</th>                       <td>    0.2009</td> <td>    0.090</td> <td>    2.235</td> <td> 0.025</td> <td>    0.025</td> <td>    0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MOBILE_LOGINS</th>                   <td>   -0.1809</td> <td>    0.098</td> <td>   -1.841</td> <td> 0.066</td> <td>   -0.373</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WEEKLY_PLAN</th>                     <td>   -0.0001</td> <td>    0.008</td> <td>   -0.016</td> <td> 0.987</td> <td>   -0.016</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EARLY_DELIVERIES</th>                <td>    0.0054</td> <td>    0.036</td> <td>    0.152</td> <td> 0.879</td> <td>   -0.064</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LATE_DELIVERIES</th>                 <td>    0.0015</td> <td>    0.025</td> <td>    0.062</td> <td> 0.950</td> <td>   -0.047</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PACKAGE_LOCKER</th>                  <td>    0.0381</td> <td>    0.123</td> <td>    0.310</td> <td> 0.757</td> <td>   -0.203</td> <td>    0.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REFRIGERATED_LOCKER</th>             <td>    0.4719</td> <td>    0.199</td> <td>    2.376</td> <td> 0.017</td> <td>    0.083</td> <td>    0.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AVG_PREP_VID_TIME</th>               <td>   -0.0008</td> <td>    0.002</td> <td>   -0.336</td> <td> 0.737</td> <td>   -0.006</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LARGEST_ORDER_SIZE</th>              <td>   -0.0004</td> <td>    0.058</td> <td>   -0.007</td> <td> 0.994</td> <td>   -0.113</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MASTER_CLASSES_ATTENDED</th>         <td>    0.1549</td> <td>    0.124</td> <td>    1.250</td> <td> 0.211</td> <td>   -0.088</td> <td>    0.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MEDIAN_MEAL_RATING</th>              <td>   -0.0573</td> <td>    0.145</td> <td>   -0.396</td> <td> 0.692</td> <td>   -0.341</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AVG_CLICKS_PER_VISIT</th>            <td>   -0.0346</td> <td>    0.043</td> <td>   -0.799</td> <td> 0.425</td> <td>   -0.120</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TOTAL_PHOTOS_VIEWED</th>             <td>    0.0001</td> <td>    0.001</td> <td>    0.207</td> <td> 0.836</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_REVENUE</th>                     <td>    0.3200</td> <td>    0.415</td> <td>    0.771</td> <td> 0.441</td> <td>   -0.494</td> <td>    1.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_TOTAL_MEALS_ORDERED</th>         <td>   -1.4216</td> <td>    0.387</td> <td>   -3.670</td> <td> 0.000</td> <td>   -2.181</td> <td>   -0.662</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_UNIQUE_MEALS_PURCH</th>          <td>    0.1016</td> <td>    0.595</td> <td>    0.171</td> <td> 0.865</td> <td>   -1.066</td> <td>    1.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_AVG_TIME_PER_SITE_VISIT</th>     <td>   -0.4048</td> <td>    0.465</td> <td>   -0.870</td> <td> 0.384</td> <td>   -1.317</td> <td>    0.507</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_CONTACTS_W_CUSTOMER_SERVICE</th> <td>    1.5072</td> <td>    0.739</td> <td>    2.038</td> <td> 0.042</td> <td>    0.058</td> <td>    2.956</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_CANCELLATIONS_BEFORE_NOON</th>   <td>   -0.6005</td> <td>    0.513</td> <td>   -1.170</td> <td> 0.242</td> <td>   -1.606</td> <td>    0.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_CANCELLATIONS_AFTER_NOON</th>    <td>   -0.3445</td> <td>    0.451</td> <td>   -0.764</td> <td> 0.445</td> <td>   -1.228</td> <td>    0.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_WEEKLY_PLAN</th>                 <td>    0.0327</td> <td>    0.279</td> <td>    0.117</td> <td> 0.907</td> <td>   -0.515</td> <td>    0.580</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_EARLY_DELIVERIES</th>            <td>    0.2214</td> <td>    0.299</td> <td>    0.740</td> <td> 0.459</td> <td>   -0.365</td> <td>    0.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_LATE_DELIVERIES</th>             <td>    0.2006</td> <td>    0.316</td> <td>    0.634</td> <td> 0.526</td> <td>   -0.420</td> <td>    0.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_AVG_PREP_VID_TIME</th>           <td>    0.9484</td> <td>    0.357</td> <td>    2.657</td> <td> 0.008</td> <td>    0.249</td> <td>    1.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_MASTER_CLASSES_ATTENDED</th>     <td>   -0.2677</td> <td>    0.262</td> <td>   -1.023</td> <td> 0.306</td> <td>   -0.781</td> <td>    0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_MEDIAN_MEAL_RATING</th>          <td>    0.3771</td> <td>    0.828</td> <td>    0.455</td> <td> 0.649</td> <td>   -1.246</td> <td>    2.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_AVG_CLICKS_PER_VISIT</th>        <td>   -1.4788</td> <td>    0.631</td> <td>   -2.345</td> <td> 0.019</td> <td>   -2.715</td> <td>   -0.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_TOTAL_PHOTOS_VIEWED</th>         <td>   -0.1928</td> <td>    0.267</td> <td>   -0.723</td> <td> 0.470</td> <td>   -0.715</td> <td>    0.330</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:     CROSS_SELL_SUCCESS   No. Observations:                 1899\n",
       "Model:                          Logit   Df Residuals:                     1860\n",
       "Method:                           MLE   Df Model:                           38\n",
       "Date:                Mon, 25 Jan 2021   Pseudo R-squ.:                 0.06737\n",
       "Time:                        22:48:03   Log-Likelihood:                -1113.2\n",
       "converged:                       True   LL-Null:                       -1193.7\n",
       "Covariance Type:            nonrobust   LLR p-value:                 4.695e-17\n",
       "===================================================================================================\n",
       "                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                          -2.5981      1.335     -1.946      0.052      -5.215       0.019\n",
       "REVENUE                            -0.0002   8.81e-05     -1.837      0.066      -0.000    1.09e-05\n",
       "TOTAL_MEALS_ORDERED                 0.0043      0.002      2.655      0.008       0.001       0.008\n",
       "UNIQUE_MEALS_PURCH                 -0.0008      0.022     -0.036      0.971      -0.045       0.043\n",
       "CONTACTS_W_CUSTOMER_SERVICE         0.0437      0.024      1.820      0.069      -0.003       0.091\n",
       "PRODUCT_CATEGORIES_VIEWED           0.0010      0.017      0.061      0.951      -0.032       0.035\n",
       "AVG_TIME_PER_SITE_VISIT             0.0011      0.001      0.945      0.345      -0.001       0.003\n",
       "MOBILE_NUMBER                       0.6755      0.151      4.471      0.000       0.379       0.972\n",
       "CANCELLATIONS_BEFORE_NOON           0.3005      0.043      6.911      0.000       0.215       0.386\n",
       "CANCELLATIONS_AFTER_NOON           -0.2060      0.155     -1.326      0.185      -0.511       0.098\n",
       "TASTES_AND_PREFERENCES              0.4416      0.113      3.922      0.000       0.221       0.662\n",
       "PC_LOGINS                           0.2009      0.090      2.235      0.025       0.025       0.377\n",
       "MOBILE_LOGINS                      -0.1809      0.098     -1.841      0.066      -0.373       0.012\n",
       "WEEKLY_PLAN                        -0.0001      0.008     -0.016      0.987      -0.016       0.016\n",
       "EARLY_DELIVERIES                    0.0054      0.036      0.152      0.879      -0.064       0.075\n",
       "LATE_DELIVERIES                     0.0015      0.025      0.062      0.950      -0.047       0.050\n",
       "PACKAGE_LOCKER                      0.0381      0.123      0.310      0.757      -0.203       0.279\n",
       "REFRIGERATED_LOCKER                 0.4719      0.199      2.376      0.017       0.083       0.861\n",
       "AVG_PREP_VID_TIME                  -0.0008      0.002     -0.336      0.737      -0.006       0.004\n",
       "LARGEST_ORDER_SIZE                 -0.0004      0.058     -0.007      0.994      -0.113       0.113\n",
       "MASTER_CLASSES_ATTENDED             0.1549      0.124      1.250      0.211      -0.088       0.398\n",
       "MEDIAN_MEAL_RATING                 -0.0573      0.145     -0.396      0.692      -0.341       0.227\n",
       "AVG_CLICKS_PER_VISIT               -0.0346      0.043     -0.799      0.425      -0.120       0.050\n",
       "TOTAL_PHOTOS_VIEWED                 0.0001      0.001      0.207      0.836      -0.001       0.001\n",
       "out_REVENUE                         0.3200      0.415      0.771      0.441      -0.494       1.134\n",
       "out_TOTAL_MEALS_ORDERED            -1.4216      0.387     -3.670      0.000      -2.181      -0.662\n",
       "out_UNIQUE_MEALS_PURCH              0.1016      0.595      0.171      0.865      -1.066       1.269\n",
       "out_AVG_TIME_PER_SITE_VISIT        -0.4048      0.465     -0.870      0.384      -1.317       0.507\n",
       "out_CONTACTS_W_CUSTOMER_SERVICE     1.5072      0.739      2.038      0.042       0.058       2.956\n",
       "out_CANCELLATIONS_BEFORE_NOON      -0.6005      0.513     -1.170      0.242      -1.606       0.405\n",
       "out_CANCELLATIONS_AFTER_NOON       -0.3445      0.451     -0.764      0.445      -1.228       0.539\n",
       "out_WEEKLY_PLAN                     0.0327      0.279      0.117      0.907      -0.515       0.580\n",
       "out_EARLY_DELIVERIES                0.2214      0.299      0.740      0.459      -0.365       0.808\n",
       "out_LATE_DELIVERIES                 0.2006      0.316      0.634      0.526      -0.420       0.821\n",
       "out_AVG_PREP_VID_TIME               0.9484      0.357      2.657      0.008       0.249       1.648\n",
       "out_MASTER_CLASSES_ATTENDED        -0.2677      0.262     -1.023      0.306      -0.781       0.245\n",
       "out_MEDIAN_MEAL_RATING              0.3771      0.828      0.455      0.649      -1.246       2.000\n",
       "out_AVG_CLICKS_PER_VISIT           -1.4788      0.631     -2.345      0.019      -2.715      -0.243\n",
       "out_TOTAL_PHOTOS_VIEWED            -0.1928      0.267     -0.723      0.470      -0.715       0.330\n",
       "===================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a logistic regression model object - BASE MODEL\n",
    "logistic_full = smf.logit(formula = \"\"\" CROSS_SELL_SUCCESS ~REVENUE + \n",
    "                                                     TOTAL_MEALS_ORDERED + \n",
    "                                                     UNIQUE_MEALS_PURCH + \n",
    "                                                     CONTACTS_W_CUSTOMER_SERVICE + \n",
    "                                                     PRODUCT_CATEGORIES_VIEWED + \n",
    "                                                     AVG_TIME_PER_SITE_VISIT + \n",
    "                                                     MOBILE_NUMBER + \n",
    "                                                     CANCELLATIONS_BEFORE_NOON + \n",
    "                                                     CANCELLATIONS_AFTER_NOON + \n",
    "                                                     TASTES_AND_PREFERENCES + \n",
    "                                                     PC_LOGINS + \n",
    "                                                     MOBILE_LOGINS + \n",
    "                                                     WEEKLY_PLAN + \n",
    "                                                     EARLY_DELIVERIES + \n",
    "                                                     LATE_DELIVERIES + \n",
    "                                                     PACKAGE_LOCKER + \n",
    "                                                     REFRIGERATED_LOCKER + \n",
    "                                                     AVG_PREP_VID_TIME + \n",
    "                                                     LARGEST_ORDER_SIZE + \n",
    "                                                     MASTER_CLASSES_ATTENDED + \n",
    "                                                     MEDIAN_MEAL_RATING + \n",
    "                                                     AVG_CLICKS_PER_VISIT + \n",
    "                                                     TOTAL_PHOTOS_VIEWED + \n",
    "                                                     out_REVENUE + \n",
    "                                                     out_TOTAL_MEALS_ORDERED + \n",
    "                                                     out_UNIQUE_MEALS_PURCH + \n",
    "                                                     out_AVG_TIME_PER_SITE_VISIT + \n",
    "                                                     out_CONTACTS_W_CUSTOMER_SERVICE + \n",
    "                                                     out_CANCELLATIONS_BEFORE_NOON + \n",
    "                                                     out_CANCELLATIONS_AFTER_NOON + \n",
    "                                                     out_WEEKLY_PLAN + \n",
    "                                                     out_EARLY_DELIVERIES + \n",
    "                                                     out_LATE_DELIVERIES + \n",
    "                                                     out_AVG_PREP_VID_TIME + \n",
    "                                                     out_MASTER_CLASSES_ATTENDED + \n",
    "                                                     out_MEDIAN_MEAL_RATING + \n",
    "                                                     out_AVG_CLICKS_PER_VISIT + \n",
    "                                                     out_TOTAL_PHOTOS_VIEWED\"\"\",\n",
    "                                                        data   = original_df)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_full = logistic_full.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring set of x-variables (NEW)\n",
    "x_var = ['TOTAL_MEALS_ORDERED','MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON',\n",
    "         'TASTES_AND_PREFERENCES', 'PC_LOGINS', 'REFRIGERATED_LOCKER', \n",
    "         'out_TOTAL_MEALS_ORDERED', 'out_CONTACTS_W_CUSTOMER_SERVICE',\n",
    "         'out_AVG_PREP_VID_TIME', 'out_AVG_CLICKS_PER_VISIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.6917\n",
      "Testing  ACCURACY: 0.6968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mccah\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5482787317825681"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/test split with the full model\n",
    "original_df_data   =  original_df.loc[ : , x_var]\n",
    "original_df_target =  original_df.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "\n",
    "# this is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            original_df_data,\n",
    "            original_df_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.25,\n",
    "            stratify     = original_df_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = sklearn.linear_model.LogisticRegression(solver = 'lbfgs',\n",
    "                                                 C = 1,\n",
    "                                                 random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "# area under the roc curve (auc)\n",
    "roc_auc_score(y_true  = y_test,\n",
    "              y_score = logreg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Model', 'Training Accuracy', 'Testing Accuracy', 'AUC Value']\n",
      "['Logistic Regression', 0.6917, 0.6968, 0.5483]\n"
     ]
    }
   ],
   "source": [
    "# creating an empty list\n",
    "model_performance = [['Model', 'Training Accuracy',\n",
    "                      'Testing Accuracy', 'AUC Value']]\n",
    "\n",
    "\n",
    "# train accuracy\n",
    "logreg_train_acc  = logreg_fit.score(x_train, y_train).round(4)\n",
    "\n",
    "\n",
    "# test accuracy\n",
    "logreg_test_acc   = logreg_fit.score(x_test, y_test).round(4)\n",
    "\n",
    "\n",
    "# auc value\n",
    "logreg_auc = roc_auc_score(y_true  = y_test,\n",
    "                           y_score = logreg_pred).round(4)\n",
    "\n",
    "\n",
    "# saving the results\n",
    "model_performance.append(['Logistic Regression',\n",
    "                          logreg_train_acc,\n",
    "                          logreg_test_acc,\n",
    "                          logreg_auc])\n",
    "\n",
    "\n",
    "# checking the results\n",
    "for model in model_performance:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 20 133]\n",
      " [ 11 311]]\n"
     ]
    }
   ],
   "source": [
    "# creating a confusion matrix\n",
    "print(confusion_matrix(y_true = y_test,\n",
    "                       y_pred = logreg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 20\n",
      "False Positives: 133\n",
      "False Negatives: 11\n",
      "True Positives : 311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5483\n"
     ]
    }
   ],
   "source": [
    "# area under the roc curve (auc)\n",
    "print(roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# display_tree\n",
    "########################################\n",
    "def display_tree(tree, feature_df, height = 500, width = 800, export = False):\n",
    "    \"\"\"\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    tree       : fitted tree model object\n",
    "        fitted CART model to visualized\n",
    "    feature_df : DataFrame\n",
    "        DataFrame of explanatory features (used to generate labels)\n",
    "    height     : int, default 500\n",
    "        height in pixels to which to constrain image in html\n",
    "    width      : int, default 800\n",
    "        width in pixels to which to constrain image in html\n",
    "    export     : bool, defalut False\n",
    "        whether or not to export the tree as a .png file\n",
    "    \"\"\"\n",
    "\n",
    "    # visualizing the tree\n",
    "    dot_data = StringIO()\n",
    "\n",
    "    \n",
    "    # exporting tree to graphviz\n",
    "    export_graphviz(decision_tree      = tree,\n",
    "                    out_file           = dot_data,\n",
    "                    filled             = True,\n",
    "                    rounded            = True,\n",
    "                    special_characters = True,\n",
    "                    feature_names      = feature_df.columns)\n",
    "\n",
    "\n",
    "    # declaring a graph object\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "\n",
    "    # creating image\n",
    "    img = Image(graph.create_png(),\n",
    "                height = height,\n",
    "                width  = width,\n",
    "                unconfined = True)\n",
    "\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Tree Training ACCURACY: 0.9249\n",
      "Full Tree Testing ACCURACY : 0.5347\n",
      "Full Tree AUC Score: 0.5059\n"
     ]
    }
   ],
   "source": [
    "#INSTANTIATING a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Full Tree Training ACCURACY:', full_tree_fit.score(x_train,\n",
    "                                                    y_train).round(4))\n",
    "\n",
    "print('Full Tree Testing ACCURACY :', full_tree_fit.score(x_test,\n",
    "                                                    y_test).round(4))\n",
    "\n",
    "print('Full Tree AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "full_tree_train_score = full_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 65\n",
      "False Positives: 88\n",
      "False Negatives: 133\n",
      "True Positives : 189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {full_tree_tn}\n",
    "False Positives: {full_tree_fp}\n",
    "False Negatives: {full_tree_fn}\n",
    "True Positives : {full_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.6931\n",
      "Testing  ACCURACY: 0.6779\n",
      "AUC Score        : 0.5377\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "pruned_tree = DecisionTreeClassifier(max_depth = 4,\n",
    "                                     min_samples_leaf = 25,\n",
    "                                     random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "pruned_tree_fit  = pruned_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "pruned_tree_pred = pruned_tree_fit.predict(x_test)\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', pruned_tree_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', pruned_tree_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = pruned_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = pruned_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = pruned_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = pruned_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 22\n",
      "False Positives: 131\n",
      "False Negatives: 22\n",
      "True Positives : 300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = pruned_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# display_tree\n",
    "########################################\n",
    "def display_tree(tree, feature_df, height = 500, width = 800, export = False):\n",
    "    \"\"\"\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    tree       : fitted tree model object\n",
    "        fitted CART model to visualized\n",
    "    feature_df : DataFrame\n",
    "        DataFrame of explanatory features (used to generate labels)\n",
    "    height     : int, default 500\n",
    "        height in pixels to which to constrain image in html\n",
    "    width      : int, default 800\n",
    "        width in pixels to which to constrain image in html\n",
    "    export     : bool, defalut False\n",
    "        whether or not to export the tree as a .png file\n",
    "    \"\"\"\n",
    "\n",
    "    # visualizing the tree\n",
    "    dot_data = StringIO()\n",
    "\n",
    "    \n",
    "    # exporting tree to graphviz\n",
    "    export_graphviz(decision_tree      = tree,\n",
    "                    out_file           = dot_data,\n",
    "                    filled             = True,\n",
    "                    rounded            = True,\n",
    "                    special_characters = True,\n",
    "                    feature_names      = feature_df.columns)\n",
    "\n",
    "\n",
    "    # declaring a graph object\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "\n",
    "    # creating image\n",
    "    img = Image(graph.create_png(),\n",
    "                height = height,\n",
    "                width  = width,\n",
    "                unconfined = True)\n",
    "\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a logistic regression model with default values\n",
    "lr_default = LogisticRegression(solver = 'lbfgs',\n",
    "                                C = 1.0,\n",
    "                                warm_start = False,\n",
    "                                random_state = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.6917\n",
      "Testing  ACCURACY: 0.6968\n",
      "AUC Score        : 0.5483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mccah\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# FITTING the training data\n",
    "lr_default_fit = lr_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "lr_default_pred = lr_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', lr_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', lr_default_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# SCORING with AUC\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = lr_default_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = lr_default_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = lr_default_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = lr_default_pred).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model         AUC Score      TN, FP, FN, TP\n",
      "-----         ---------      --------------\n",
      "Logistic      0.5483         (20, 133, 11, 311)\n",
      "Full Tree     0.5059         (65, 88, 133, 189)\n",
      "Pruned Tree   0.5377         (22, 131, 22, 300)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparing results\n",
    "print(f\"\"\"\n",
    "Model         AUC Score      TN, FP, FN, TP\n",
    "-----         ---------      --------------\n",
    "Logistic      {logreg_auc_score}         {logreg_tn, logreg_fp, logreg_fn, logreg_tp}\n",
    "Full Tree     {full_tree_auc_score}         {full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp}\n",
    "Pruned Tree   {pruned_tree_auc_score}         {pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Name'    : ['Logistic', 'Full Tree', 'Pruned Tree'],\n",
    "           \n",
    "    'AUC Score' : [logreg_auc_score, full_tree_auc_score, pruned_tree_auc_score],\n",
    "    \n",
    "    'Training Accuracy' : [logreg_train_score, full_tree_train_score,\n",
    "                           pruned_tree_train_score],\n",
    "           \n",
    "    'Testing Accuracy'  : [logreg_test_score, full_tree_test_score,\n",
    "                           pruned_tree_test_score],\n",
    "\n",
    "    'Confusion Matrix'  : [(logreg_tn, logreg_fp, logreg_fn, logreg_tp),\n",
    "                           (full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp),\n",
    "                           (pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp)]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################\n",
    "#RandomizedSearchCV\n",
    "########################################\n",
    "\n",
    "#declaring a hyperparameter space\n",
    "C_space          = pd.np.arange(0.1, 5.0, 0.1)\n",
    "warm_start_space = [True, False]\n",
    "solver_space     = ['newton-cg', 'sag', 'lbfgs']\n",
    "\n",
    "\n",
    "#creating a hyperparameter grid\n",
    "param_grid = {'C'          : C_space,\n",
    "              'warm_start' : warm_start_space,\n",
    "              'solver'     : solver_space}\n",
    "\n",
    "\n",
    "#INSTANTIATING the model object without hyperparameters\n",
    "lr_tuned = LogisticRegression(random_state = 219,\n",
    "                              max_iter     = 1000)\n",
    "\n",
    "\n",
    "#GridSearchCV object\n",
    "lr_tuned_cv = RandomizedSearchCV(estimator           = lr_tuned,   # the model object\n",
    "                                 param_distributions = param_grid, # parameters to tune\n",
    "                                 cv                  = 3,          # how many folds in cross-validation\n",
    "                                 n_iter              = 250,        # number of combinations of hyperparameters to try\n",
    "                                 random_state        = 219,        # starting point for random sequence\n",
    "                                 scoring = make_scorer(\n",
    "                                           roc_auc_score,\n",
    "                                           needs_threshold = False)) # scoring criteria (AUC)\n",
    "\n",
    "\n",
    "#FITTING to the FULL DATASET (due to cross-validation)\n",
    "lr_tuned_cv.fit(original_df_data, original_df_target)\n",
    "\n",
    "\n",
    "#PREDICT step is not needed\n",
    "\n",
    "\n",
    "#printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#checking the best estimator for the model\n",
    "lr_tuned_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.6903\n",
      "Testing  ACCURACY: 0.7095\n",
      "AUC Score        : 0.5747\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "lr_tuned = LogisticRegression(C=4.9, max_iter=1000, random_state=219, warm_start=True)\n",
    "\n",
    "\n",
    "# FIT step is not needed\n",
    "lr_tuned_fit=lr_tuned.fit(original_df_data, original_df_target)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "lr_tuned_pred = lr_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', lr_tuned.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', lr_tuned.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                  y_score = lr_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lr_tuned_train_score = lr_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "lr_tuned_test_score  = lr_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "lr_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = lr_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 30\n",
      "False Positives: 123\n",
      "False Negatives: 15\n",
      "True Positives : 307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "lr_tuned_tn, \\\n",
    "lr_tuned_fp, \\\n",
    "lr_tuned_fn, \\\n",
    "lr_tuned_tp = confusion_matrix(y_true = y_test, y_pred = lr_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {lr_tuned_tn}\n",
    "False Positives: {lr_tuned_fp}\n",
    "False Negatives: {lr_tuned_fn}\n",
    "True Positives : {lr_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>(20, 133, 11, 311)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.5059</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>(65, 88, 133, 189)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.5377</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.6779</td>\n",
       "      <td>(22, 131, 22, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.5747</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>(30, 123, 15, 307)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model Name  AUC Score  Training Accuracy  Testing Accuracy    Confusion Matrix\n",
       "0     Logistic     0.5483             0.6917            0.6968  (20, 133, 11, 311)\n",
       "1    Full Tree     0.5059             0.9249            0.5347  (65, 88, 133, 189)\n",
       "2  Pruned Tree     0.5377             0.6931            0.6779  (22, 131, 22, 300)\n",
       "3     Tuned LR     0.5747             0.6903            0.7095  (30, 123, 15, 307)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "lr_train_acc = lr_tuned.score(x_train, y_train).round(4)\n",
    "lr_test_acc  = lr_tuned.score(x_test, y_test).round(4)\n",
    "lr_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = lr_tuned_pred).round(4)\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'             : 'Tuned LR',\n",
    "                          'Training Accuracy'  : lr_train_acc,\n",
    "                          'Testing Accuracy'   : lr_test_acc,\n",
    "                          'AUC Score'          : lr_auc,\n",
    "                          'Confusion Matrix'   : (lr_tuned_tn,\n",
    "                                                  lr_tuned_fp,\n",
    "                                                  lr_tuned_fn,\n",
    "                                                  lr_tuned_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#declaring a hyperparameter space\n",
    "criterion_space = ['gini', 'entropy']\n",
    "splitter_space  = ['best', 'random']\n",
    "depth_space     = pd.np.arange(1, 25, 1)\n",
    "leaf_space      = pd.np.arange(1, 100, 1)\n",
    "\n",
    "\n",
    "#creating a hyperparameter grid\n",
    "param_grid = {'criterion'        : criterion_space,\n",
    "              'splitter'         : splitter_space,\n",
    "              'max_depth'        : depth_space,\n",
    "              'min_samples_leaf' : leaf_space}\n",
    "\n",
    "\n",
    "#INSTANTIATING the model object without hyperparameters\n",
    "tuned_tree = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "#RandomizedSearchCV object\n",
    "tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "                                   param_distributions   = param_grid,\n",
    "                                   cv                    = 3,\n",
    "                                   n_iter                = 1000,\n",
    "                                   random_state          = 219,\n",
    "                                   scoring = make_scorer(roc_auc_score,\n",
    "                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "#FITTING to the FULL DATASET (due to cross-validation)\n",
    "tuned_tree_cv.fit(original_df_data, original_df_target)\n",
    "\n",
    "\n",
    "#PREDICT step is not needed\n",
    "\n",
    "\n",
    "#printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#best estimators based on RandomizedSearchCV\n",
    "tuned_tree_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.6945\n",
      "Testing  ACCURACY: 0.7032\n",
      "AUC Score        : 0.5735\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "tree_tuned = DecisionTreeClassifier(criterion='entropy', max_depth=18, min_samples_leaf=42,\n",
    "                       random_state=219)\n",
    "\n",
    "# FIT step is not needed\n",
    "tuned_tuned_fit=tree_tuned.fit(original_df_data, original_df_target)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "tree_tuned_pred = tree_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', tree_tuned.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tree_tuned_train_score = tree_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "tree_tuned_test_score  = tree_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "tree_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = tree_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 32\n",
      "False Positives: 121\n",
      "False Negatives: 20\n",
      "True Positives : 302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_tree_tn, \\\n",
    "tuned_tree_fp, \\\n",
    "tuned_tree_fn, \\\n",
    "tuned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_tree_tn}\n",
    "False Positives: {tuned_tree_fp}\n",
    "False Negatives: {tuned_tree_fn}\n",
    "True Positives : {tuned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>(20, 133, 11, 311)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.5059</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>(65, 88, 133, 189)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.5377</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.6779</td>\n",
       "      <td>(22, 131, 22, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.5747</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>(30, 123, 15, 307)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.5735</td>\n",
       "      <td>0.6945</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>(32, 121, 20, 302)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model Name  AUC Score  Training Accuracy  Testing Accuracy    Confusion Matrix\n",
       "0     Logistic     0.5483             0.6917            0.6968  (20, 133, 11, 311)\n",
       "1    Full Tree     0.5059             0.9249            0.5347  (65, 88, 133, 189)\n",
       "2  Pruned Tree     0.5377             0.6931            0.6779  (22, 131, 22, 300)\n",
       "3     Tuned LR     0.5747             0.6903            0.7095  (30, 123, 15, 307)\n",
       "4   Tuned Tree     0.5735             0.6945            0.7032  (32, 121, 20, 302)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "tree_train_acc = tree_tuned.score(x_train, y_train).round(4)\n",
    "tree_test_acc  = tree_tuned.score(x_test, y_test).round(4)\n",
    "tree_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = tree_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned Tree',\n",
    "                           'Training Accuracy' : tree_train_acc,\n",
    "                           'Testing Accuracy'  : tree_test_acc,\n",
    "                           'AUC Score'         : tree_auc,\n",
    "                           'Confusion Matrix'  : (tuned_tree_tn,\n",
    "                                                  tuned_tree_fp,\n",
    "                                                  tuned_tree_fn,\n",
    "                                                  tuned_tree_tp)},\n",
    "                           ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(pd.np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 100,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = None,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.9249\n",
      "Testing  ACCURACY: 0.6\n",
      "AUC Score        : 0.5317\n"
     ]
    }
   ],
   "source": [
    "# FITTING the training data\n",
    "rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 52\n",
      "False Positives: 101\n",
      "False Negatives: 89\n",
      "True Positives : 233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "rf_tn, \\\n",
    "rf_fp, \\\n",
    "rf_fn, \\\n",
    "rf_tp = confusion_matrix(y_true = y_test, y_pred = rf_default_fit_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {rf_tn}\n",
    "False Positives: {rf_fp}\n",
    "False Negatives: {rf_fn}\n",
    "True Positives : {rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>(20, 133, 11, 311)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.5059</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>(65, 88, 133, 189)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.5377</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.6779</td>\n",
       "      <td>(22, 131, 22, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.5747</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>(30, 123, 15, 307)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.5735</td>\n",
       "      <td>0.6945</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>(32, 121, 20, 302)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest (Full)</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>(52, 101, 89, 233)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model Name  AUC Score  Training Accuracy  Testing Accuracy    Confusion Matrix\n",
       "0              Logistic     0.5483             0.6917            0.6968  (20, 133, 11, 311)\n",
       "1             Full Tree     0.5059             0.9249            0.5347  (65, 88, 133, 189)\n",
       "2           Pruned Tree     0.5377             0.6931            0.6779  (22, 131, 22, 300)\n",
       "3              Tuned LR     0.5747             0.6903            0.7095  (30, 123, 15, 307)\n",
       "4            Tuned Tree     0.5735             0.6945            0.7032  (32, 121, 20, 302)\n",
       "5  Random Forest (Full)     0.5317             0.9249            0.6000  (52, 101, 89, 233)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "rf_train_acc = rf_default_fit.score(x_train, y_train).round(4)\n",
    "rf_test_acc  = rf_default_fit.score(x_test, y_test).round(4)\n",
    "rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = rf_default_fit_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'         : 'Random Forest (Full)',\n",
    "                           'Training Accuracy'  : rf_train_acc,\n",
    "                           'Testing Accuracy'   : rf_test_acc,\n",
    "                           'AUC Score'          : rf_auc,\n",
    "                           'Confusion Matrix'   : (rf_tn,\n",
    "                                                   rf_fp,\n",
    "                                                   rf_fn,\n",
    "                                                   rf_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#FITTING the training data\n",
    "rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "#Declaring a hyperparameter space\n",
    "estimator_space  = pd.np.arange(100, 1100, 250)\n",
    "leaf_space       = pd.np.arange(1, 31, 10)\n",
    "criterion_space  = ['gini', 'entropy']\n",
    "bootstrap_space  = [True, False]\n",
    "warm_start_space = [True, False]\n",
    "\n",
    "\n",
    "#Creating a hyperparameter grid\n",
    "param_grid = {'n_estimators'     : estimator_space,\n",
    "              'min_samples_leaf' : leaf_space,\n",
    "              'criterion'        : criterion_space,\n",
    "              'bootstrap'        : bootstrap_space,\n",
    "              'warm_start'       : warm_start_space}\n",
    "\n",
    "\n",
    "#INSTANTIATING the model object without hyperparameters\n",
    "forest_grid = RandomForestClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "#GridSearchCV object\n",
    "forest_cv = RandomizedSearchCV(estimator           = forest_grid,\n",
    "                               param_distributions = param_grid,\n",
    "                               cv         = 3,\n",
    "                               n_iter     = 1000,\n",
    "                               scoring    = make_scorer(roc_auc_score,\n",
    "                                            needs_threshold = False))\n",
    "\n",
    "\n",
    "#FITTING to the FULL DATASET (due to cross-validation)\n",
    "forest_cv.fit(original_df_data, original_df_target)\n",
    "\n",
    "\n",
    "#printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", forest_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#checking the best estimator for the model\n",
    "forest_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Tuned Training ACCURACY: 0.7001\n",
      "Forest Tuned Testing  ACCURACY: 0.6968\n",
      "Forest Tuned AUC Score        : 0.538\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "forest_tuned = RandomForestClassifier(criterion='entropy', n_estimators=350, random_state=219,\n",
    "                       warm_start=True)\n",
    "\n",
    "# FIT step is not needed\n",
    "forest_tuned_fit=tree_tuned.fit(original_df_data, original_df_target)\n",
    "\n",
    "# copy/pasting in the best_estimator_ results\n",
    "# to avoid running another RandomizedSearch\n",
    "forest_tuned = RandomForestClassifier(criterion='entropy',\n",
    "                                      min_samples_leaf=11,\n",
    "                                      n_estimators=350,\n",
    "                                      random_state=219, \n",
    "                                      warm_start=True)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "forest_tuned_fit = forest_tuned.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "forest_tuned_pred = forest_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Forest Tuned Training ACCURACY:', forest_tuned.score(x_train, y_train).round(4))\n",
    "print('Forest Tuned Testing  ACCURACY:', forest_tuned.score(x_test, y_test).round(4))\n",
    "print('Forest Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                                       y_score = forest_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "forest_tuned_train_score = forest_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "forest_tuned_test_score  = forest_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "forest_tuned_auc = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = forest_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 14\n",
      "False Positives: 139\n",
      "False Negatives: 5\n",
      "True Positives : 317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_rf_tn, \\\n",
    "tuned_rf_fp, \\\n",
    "tuned_rf_fn, \\\n",
    "tuned_rf_tp = confusion_matrix(y_true = y_test, y_pred = forest_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_rf_tn}\n",
    "False Positives: {tuned_rf_fp}\n",
    "False Negatives: {tuned_rf_fn}\n",
    "True Positives : {tuned_rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>(20, 133, 11, 311)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.5059</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>(65, 88, 133, 189)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.5377</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.6779</td>\n",
       "      <td>(22, 131, 22, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.5747</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>(30, 123, 15, 307)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.5735</td>\n",
       "      <td>0.6945</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>(32, 121, 20, 302)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest (Full)</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>(52, 101, 89, 233)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuned Random Forest (Full)</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.7001</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>(14, 139, 5, 317)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Name  AUC Score  Training Accuracy  Testing Accuracy    Confusion Matrix\n",
       "0                    Logistic     0.5483             0.6917            0.6968  (20, 133, 11, 311)\n",
       "1                   Full Tree     0.5059             0.9249            0.5347  (65, 88, 133, 189)\n",
       "2                 Pruned Tree     0.5377             0.6931            0.6779  (22, 131, 22, 300)\n",
       "3                    Tuned LR     0.5747             0.6903            0.7095  (30, 123, 15, 307)\n",
       "4                  Tuned Tree     0.5735             0.6945            0.7032  (32, 121, 20, 302)\n",
       "5        Random Forest (Full)     0.5317             0.9249            0.6000  (52, 101, 89, 233)\n",
       "6  Tuned Random Forest (Full)     0.5380             0.7001            0.6968   (14, 139, 5, 317)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "tuned_rf_train_acc = forest_tuned_fit.score(x_train, y_train).round(4)\n",
    "tuned_rf_test_acc  = forest_tuned_fit.score(x_test, y_test).round(4)\n",
    "tuned_rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                                   y_score = forest_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'         : 'Tuned Random Forest (Full)',\n",
    "                           'Training Accuracy'  : tuned_rf_train_acc,\n",
    "                           'Testing Accuracy'   : tuned_rf_test_acc,\n",
    "                           'AUC Score'          : tuned_rf_auc,\n",
    "                           'Confusion Matrix'   : (tuned_rf_tn,\n",
    "                                                   tuned_rf_fp,\n",
    "                                                   tuned_rf_fn,\n",
    "                                                   tuned_rf_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7331\n",
      "Testing ACCURACY : 0.6821\n",
      "AUC Score        : 0.546\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING the model object without hyperparameters\n",
    "full_gbm_default = GradientBoostingClassifier(loss          = 'deviance',\n",
    "                                              learning_rate = 0.1,\n",
    "                                              n_estimators  = 100,\n",
    "                                              criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 3,\n",
    "                                              warm_start    = False,\n",
    "                                              random_state  = 219)\n",
    "\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "full_gbm_default_fit = full_gbm_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "full_gbm_default_pred = full_gbm_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', full_gbm_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_default_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_default_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 25\n",
      "False Positives: 128\n",
      "False Negatives: 23\n",
      "True Positives : 299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_default_tn, \\\n",
    "gbm_default_fp, \\\n",
    "gbm_default_fn, \\\n",
    "gbm_default_tp = confusion_matrix(y_true = y_test, y_pred = full_gbm_default_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_default_tn}\n",
    "False Positives: {gbm_default_fp}\n",
    "False Negatives: {gbm_default_fn}\n",
    "True Positives : {gbm_default_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>(20, 133, 11, 311)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.5059</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>(65, 88, 133, 189)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.5377</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.6779</td>\n",
       "      <td>(22, 131, 22, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.5747</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>(30, 123, 15, 307)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.5735</td>\n",
       "      <td>0.6945</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>(32, 121, 20, 302)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest (Full)</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>(52, 101, 89, 233)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuned Random Forest (Full)</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.7001</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>(14, 139, 5, 317)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBM (Full)</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.6821</td>\n",
       "      <td>(25, 128, 23, 299)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Name  AUC Score  Training Accuracy  Testing Accuracy    Confusion Matrix\n",
       "0                    Logistic     0.5483             0.6917            0.6968  (20, 133, 11, 311)\n",
       "1                   Full Tree     0.5059             0.9249            0.5347  (65, 88, 133, 189)\n",
       "2                 Pruned Tree     0.5377             0.6931            0.6779  (22, 131, 22, 300)\n",
       "3                    Tuned LR     0.5747             0.6903            0.7095  (30, 123, 15, 307)\n",
       "4                  Tuned Tree     0.5735             0.6945            0.7032  (32, 121, 20, 302)\n",
       "5        Random Forest (Full)     0.5317             0.9249            0.6000  (52, 101, 89, 233)\n",
       "6  Tuned Random Forest (Full)     0.5380             0.7001            0.6968   (14, 139, 5, 317)\n",
       "7                  GBM (Full)     0.5460             0.7331            0.6821  (25, 128, 23, 299)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SCORING the model\n",
    "gbm_train_acc = full_gbm_default_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = full_gbm_default_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  =y_test,\n",
    "                              y_score = full_gbm_default_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'       : 'GBM (Full)',\n",
    "                          'Training Accuracy' : gbm_train_acc,\n",
    "                          'Testing Accuracy'  : gbm_test_acc,\n",
    "                          'AUC Score'         : gbm_auc,\n",
    "                          'Confusion Matrix'  : (gbm_default_tn,\n",
    "                                                 gbm_default_fp,\n",
    "                                                 gbm_default_fn,\n",
    "                                                 gbm_default_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Declaring a hyperparameter space\n",
    "learn_space        = pd.np.arange(0.1, 2.0, 0.2)\n",
    "estimator_space    = pd.np.arange(100, 200, 25)\n",
    "depth_space        = pd.np.arange(1, 20, 2)\n",
    "warm_start_space   = [True, False]\n",
    "\n",
    "#Creating a hyperparameter grid\n",
    "param_grid = {'learning_rate' : learn_space,\n",
    "              'max_depth'     : depth_space,\n",
    "              'n_estimators'  : estimator_space,\n",
    "              'warm_start'     : warm_start_space}\n",
    "#INSTANTIATING the model object without hyperparameters\n",
    "full_gbm_grid = GradientBoostingClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "#GridSearchCV object\n",
    "full_gbm_cv = RandomizedSearchCV(estimator     = full_gbm_grid,\n",
    "                           param_distributions = param_grid,\n",
    "                           cv                  = 3,\n",
    "                           n_iter              = 500,\n",
    "                           random_state        = 219,\n",
    "                           scoring             = make_scorer(roc_auc_score,\n",
    "                                                 needs_threshold = False))\n",
    "\n",
    "\n",
    "#FITTING to the FULL DATASET (due to cross-validation)\n",
    "full_gbm_cv.fit(original_df_data, original_df_target)\n",
    "\n",
    "#PREDICT step is not needed\n",
    "\n",
    "\n",
    "#printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", full_gbm_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", full_gbm_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#checking the best estimator for the model\n",
    " full_gbm_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8111\n",
      "Testing  ACCURACY: 0.8168\n",
      "AUC Score        : 0.75\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING the model object without hyperparameters\n",
    "\n",
    "gbm_tuned = GradientBoostingClassifier(learning_rate=0.7000000000000001, n_estimators=125,\n",
    "                           random_state=219, warm_start=True)\n",
    "# FIT step is not needed\n",
    "gbm_tuned_fit = gbm_tuned.fit(original_df_data, original_df_target)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "gbm_tuned_pred = gbm_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', gbm_tuned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', gbm_tuned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = gbm_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 86\n",
      "False Positives: 67\n",
      "False Negatives: 20\n",
      "True Positives : 302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_tuned_tn, \\\n",
    "gbm_tuned_fp, \\\n",
    "gbm_tuned_fn, \\\n",
    "gbm_tuned_tp = confusion_matrix(y_true = y_test, y_pred = gbm_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_tuned_tn}\n",
    "False Positives: {gbm_tuned_fp}\n",
    "False Negatives: {gbm_tuned_fn}\n",
    "True Positives : {gbm_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>(20, 133, 11, 311)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.5059</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>(65, 88, 133, 189)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.5377</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.6779</td>\n",
       "      <td>(22, 131, 22, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.5747</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>(30, 123, 15, 307)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.5735</td>\n",
       "      <td>0.6945</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>(32, 121, 20, 302)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest (Full)</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>(52, 101, 89, 233)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuned Random Forest (Full)</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.7001</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>(14, 139, 5, 317)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBM (Full)</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.6821</td>\n",
       "      <td>(25, 128, 23, 299)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tuned GBM</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.8168</td>\n",
       "      <td>(86, 67, 20, 302)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Name  AUC Score  Training Accuracy  Testing Accuracy    Confusion Matrix\n",
       "0                    Logistic     0.5483             0.6917            0.6968  (20, 133, 11, 311)\n",
       "1                   Full Tree     0.5059             0.9249            0.5347  (65, 88, 133, 189)\n",
       "2                 Pruned Tree     0.5377             0.6931            0.6779  (22, 131, 22, 300)\n",
       "3                    Tuned LR     0.5747             0.6903            0.7095  (30, 123, 15, 307)\n",
       "4                  Tuned Tree     0.5735             0.6945            0.7032  (32, 121, 20, 302)\n",
       "5        Random Forest (Full)     0.5317             0.9249            0.6000  (52, 101, 89, 233)\n",
       "6  Tuned Random Forest (Full)     0.5380             0.7001            0.6968   (14, 139, 5, 317)\n",
       "7                  GBM (Full)     0.5460             0.7331            0.6821  (25, 128, 23, 299)\n",
       "8                   Tuned GBM     0.7500             0.8111            0.8168   (86, 67, 20, 302)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "gbm_train_acc = gbm_tuned_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = gbm_tuned_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = gbm_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned GBM',\n",
    "                          'Training Accuracy'  : gbm_train_acc,\n",
    "                          'Testing Accuracy'   : gbm_test_acc,\n",
    "                          'AUC Score'          : gbm_auc,\n",
    "                          'Confusion Matrix'   : (gbm_tuned_tn,\n",
    "                                                  gbm_tuned_fp,\n",
    "                                                  gbm_tuned_fn,\n",
    "                                                  gbm_tuned_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN- Final & Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_neighbors\n",
    "########################################\n",
    "def optimal_neighbors(x_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.25,\n",
    "                      seed=802,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "X_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the X data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 802\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing X_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(x_data)\n",
    "        x_scaled           = scaler.transform(x_data)\n",
    "        x_scaled_df        = pd.DataFrame(x_scaled)\n",
    "        x_data             = x_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(x_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(x_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is: 11\n"
     ]
    }
   ],
   "source": [
    "# determining the optimal number of neighbors\n",
    "opt_neighbors = optimal_neighbors(x_data        = original_df_data,\n",
    "                                  y_data        = original_df_target,\n",
    "                                  response_type = 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing explanatory variable data\n",
    "original_df_clean   = original_df.drop(['NAME', 'FIRST_NAME', 'FAMILY_NAME','EMAIL','personal','email_domain'],\n",
    "                     axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.9171\n",
      "Testing  ACCURACY: 0.8884\n",
      "AUC Score        : 0.8337\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the data\n",
    "scaler.fit(original_df_clean)\n",
    "\n",
    "\n",
    "# TRANSFORMING the data\n",
    "x_scaled     = scaler.transform(original_df_clean)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "x_scaled_df  = pd.DataFrame(x_scaled) \n",
    "\n",
    "\n",
    "# train-test split with the scaled data\n",
    "x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "            x_scaled_df,\n",
    "            original_df_target,\n",
    "            random_state = 219,\n",
    "            test_size = 0.25,\n",
    "            stratify = original_df_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = opt_neighbors)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "knn_fit = knn_opt.fit(x_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "knn_pred = knn_fit.predict(x_test_scaled)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(x_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(x_test_scaled, y_test_scaled).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data\n",
    "knn_train_score = knn_fit.score(x_train_scaled, y_train_scaled).round(4)\n",
    "knn_test_score  = knn_fit.score(x_test_scaled, y_test_scaled).round(4)\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "knn_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 104\n",
      "False Positives: 49\n",
      "False Negatives: 4\n",
      "True Positives : 318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "knn_tree_tn, \\\n",
    "knn_tree_fp, \\\n",
    "knn_tree_fn, \\\n",
    "knn_tree_tp = confusion_matrix(y_true = y_test, y_pred = knn_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {knn_tree_tn}\n",
    "False Positives: {knn_tree_fp}\n",
    "False Negatives: {knn_tree_fn}\n",
    "True Positives : {knn_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>(20, 133, 11, 311)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.5059</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>(65, 88, 133, 189)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.5377</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.6779</td>\n",
       "      <td>(22, 131, 22, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.5747</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>(30, 123, 15, 307)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.5735</td>\n",
       "      <td>0.6945</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>(32, 121, 20, 302)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest (Full)</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>(52, 101, 89, 233)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuned Random Forest (Full)</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.7001</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>(14, 139, 5, 317)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBM (Full)</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.6821</td>\n",
       "      <td>(25, 128, 23, 299)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tuned GBM</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.8168</td>\n",
       "      <td>(86, 67, 20, 302)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned KNN</td>\n",
       "      <td>0.8337</td>\n",
       "      <td>0.9171</td>\n",
       "      <td>0.8884</td>\n",
       "      <td>(104, 49, 4, 318)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Name  AUC Score  Training Accuracy  Testing Accuracy    Confusion Matrix\n",
       "0                    Logistic     0.5483             0.6917            0.6968  (20, 133, 11, 311)\n",
       "1                   Full Tree     0.5059             0.9249            0.5347  (65, 88, 133, 189)\n",
       "2                 Pruned Tree     0.5377             0.6931            0.6779  (22, 131, 22, 300)\n",
       "3                    Tuned LR     0.5747             0.6903            0.7095  (30, 123, 15, 307)\n",
       "4                  Tuned Tree     0.5735             0.6945            0.7032  (32, 121, 20, 302)\n",
       "5        Random Forest (Full)     0.5317             0.9249            0.6000  (52, 101, 89, 233)\n",
       "6  Tuned Random Forest (Full)     0.5380             0.7001            0.6968   (14, 139, 5, 317)\n",
       "7                  GBM (Full)     0.5460             0.7331            0.6821  (25, 128, 23, 299)\n",
       "8                   Tuned GBM     0.7500             0.8111            0.8168   (86, 67, 20, 302)\n",
       "9                   Tuned KNN     0.8337             0.9171            0.8884   (104, 49, 4, 318)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "knn_train_acc = knn_fit.score(x_train_scaled, y_train_scaled).round(4)\n",
    "knn_test_acc  = knn_fit.score(x_test_scaled, y_test_scaled).round(4)\n",
    "knn_auc       = roc_auc_score(y_true  = y_test_scaled,\n",
    "                              y_score = knn_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned KNN',\n",
    "                          'Training Accuracy'  : knn_train_acc,\n",
    "                          'Testing Accuracy'   : knn_test_acc,\n",
    "                          'AUC Score'          : knn_auc,\n",
    "                          'Confusion Matrix'   :(knn_tree_tn, \n",
    "                                                knn_tree_fp, \n",
    "                                                knn_tree_fn, \n",
    "                                                knn_tree_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned KNN</td>\n",
       "      <td>0.8337</td>\n",
       "      <td>0.9171</td>\n",
       "      <td>0.8884</td>\n",
       "      <td>(104, 49, 4, 318)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tuned GBM</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.8168</td>\n",
       "      <td>(86, 67, 20, 302)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.5747</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>(30, 123, 15, 307)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.5735</td>\n",
       "      <td>0.6945</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>(32, 121, 20, 302)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>(20, 133, 11, 311)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBM (Full)</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.6821</td>\n",
       "      <td>(25, 128, 23, 299)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuned Random Forest (Full)</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.7001</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>(14, 139, 5, 317)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.5377</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.6779</td>\n",
       "      <td>(22, 131, 22, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest (Full)</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>(52, 101, 89, 233)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.5059</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>(65, 88, 133, 189)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Name  AUC Score  Training Accuracy  Testing Accuracy    Confusion Matrix\n",
       "9                   Tuned KNN     0.8337             0.9171            0.8884   (104, 49, 4, 318)\n",
       "8                   Tuned GBM     0.7500             0.8111            0.8168   (86, 67, 20, 302)\n",
       "3                    Tuned LR     0.5747             0.6903            0.7095  (30, 123, 15, 307)\n",
       "4                  Tuned Tree     0.5735             0.6945            0.7032  (32, 121, 20, 302)\n",
       "0                    Logistic     0.5483             0.6917            0.6968  (20, 133, 11, 311)\n",
       "7                  GBM (Full)     0.5460             0.7331            0.6821  (25, 128, 23, 299)\n",
       "6  Tuned Random Forest (Full)     0.5380             0.7001            0.6968   (14, 139, 5, 317)\n",
       "2                 Pruned Tree     0.5377             0.6931            0.6779  (22, 131, 22, 300)\n",
       "5        Random Forest (Full)     0.5317             0.9249            0.6000  (52, 101, 89, 233)\n",
       "1                   Full Tree     0.5059             0.9249            0.5347  (65, 88, 133, 189)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance.sort_values(by = 'AUC Score',\n",
    "                              ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
